# Llama 3.2 3B Configuration
model:
  name: "meta-llama/Llama-3.2-3B-Instruct"
  max_seq_length: 2048
  quantization:
    load_in_4bit: false
  lora:
    r: 64
    alpha: 64
    dropout: 0
    target_modules:
      - "q_proj"
      - "k_proj"
      - "v_proj"
      - "o_proj"
      - "gate_proj"
      - "up_proj"
      - "down_proj"
    use_gradient_checkpointing: "unsloth"

dataset:
  name: "openai/gsm8k"
  config: "main"
  split: "train"
  preprocessing:
    system_prompt: |
      You are given a problem.
      Think about the problem and provide your working out.
      Place it between <start_working_out> and <end_working_out>.
      Then, provide your solution between <SOLUTION></SOLUTION>
    special_tokens:
      reasoning_start: "<start_working_out>"
      reasoning_end: "<end_working_out>"
      solution_start: "<SOLUTION>"
      solution_end: "</SOLUTION>"

training:
  type: "GRPO"
  config:
    learning_rate: 5e-6
    optim: "adamw_8bit"
    weight_decay: 0.1
    warmup_ratio: 0.1
    lr_scheduler: "cosine"
    batch_size: 1
    gradient_accumulation_steps: 4
    max_steps: 500
    save_steps: 250
    logging_steps: 1
    fp16: true
    bf16: false
    max_grad_norm: 1.0
  generation:
    num_generations: 4
    max_prompt_length: 256  # Will be calculated dynamically
    max_completion_length: 1792  # Will be calculated dynamically
    temperature: 0.7
    top_p: 0.9
    max_new_tokens: 100

rewards:
  functions:
    - "match_format_exactly"
    - "match_format_approximately"
    - "check_answer"
    - "check_numbers"

output:
  dir: "outputs"